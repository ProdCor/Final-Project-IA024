{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''!pip install Groq -q\n",
    "!pip install groq -q'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = '../input/Raw Text/FAQ/faq.json'\n",
    "LEGIS_PATH = '../input/Raw Text/Legislation/output_legislation_2.json'\n",
    "NORMS_PATH = '../input/Raw Text/Norms/output_prof3_v10_5_final.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_set = json.load(open(TEST_PATH, 'r'))\n",
    "legis_set = json.load(open(LEGIS_PATH, 'r'))\n",
    "norms_set = json.load(open(NORMS_PATH, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(legis_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4650, 10, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(norms_set), len(legis_set), len(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key='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')\n",
    "\n",
    "def groq_chat(content):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Em quais hipóteses a Procuradoria Geral pode exercer a representação judicial e extrajudicial de servidores da UNICAMP?\n",
      "A Procuradoria Geral da UNICAMP integra a Advocacia Pública e está vinculada à Procuradoria Geral do Estado, para fins de atuação uniforme e coordenada, nos termos do artigo 101 da Constituição Estadual. Além disso, é o órgão de representação jurídica da Universidade e de assessoramento jurídico da Reitoria, consoante prevê o artigo 95 do Regimento Geral da UNICAMP. Desta forma, conforme previsão regimental, a Procuradoria Geral tem a função institucional de defender os interesses da universidade, enquanto autarquia estadual, estritamente vinculada ao atendimento do interesse público. A representação judicial ou extrajudicial de servidor com vínculo funcional permanente poderá ocorrer em caráter excepcional, nas hipóteses em que o ato impugnado decorrer do exercício de suas atribuições constitucionais, legais ou regulamentares, quando o ato praticado tiver seguido a orientação jurídica da Procuradoria e desde que não haja conflito de interesses, sempre com autorização expressa do Reitor.\n",
      "----------------------------------------------------------------------\n",
      "1: Como ocorrem as atividades de cooperação, pesquisa, ensino, extensão e prestação de serviços entre a Unicamp e terceiros, pessoas físicas ou jurídicas?\n",
      "Nos termos do art. 1° da Deliberação CONSU-A-016/2022, a atuação da Universidade em atividades de cooperação, pesquisa, ensino, extensão e prestação de serviços junto a terceiros, pessoas físicas ou jurídicas, deve ocorrer mediante prévia celebração de convênios, contratos e instrumentos similares.\n",
      "----------------------------------------------------------------------\n",
      "2: Qual é o procedimento para a celebração de convênios, contratos e instrumentos similares relativos às atividades de cooperação, pesquisa, ensino, extensão e prestação de serviços pela Unicamp?\n",
      "Na Unicamp, a celebração de convênios, contratos e instrumentos similares (aqui sempre referidos como “convênios”) é regulamentada pela Deliberação CONSU-A-016/2022. O servidor responsável pela proposta de convênio deve providenciar a abertura de um processo administrativo na Unidade ou Órgão onde a atividade principal será realizada, instruí-lo com os documentos indicados e tramitá-lo conforme o disposto na Deliberação CONSU-A-016/2022. Ao final da tramitação, se devidamente aprovado em todas as instâncias, o convênio será encaminhado para assinatura da autoridade competente.\n",
      "----------------------------------------------------------------------\n",
      "3: Qual é o sistema utilizado para a tramitação dos convênios?\n",
      "Os documentos essenciais estão elencados no art. 2º da Deliberação CONSU-A-016/2022. É importante que o Executor tenha em mente que estes são os documentos mínimos necessários, mas dependendo do objeto do convênio, outros documentos podem ser demandados. O processo do convênio deve se iniciar com o documento de apresentação da proposta elaborado por seu Executor, com a indicação dos motivos pelos quais apresenta a proposta e por que entende que sua celebração é conveniente e oportuna para a Universidade. A apresentação da proposta deve ser seguida dos demais documentos elencados no mencionado artigo 2º, além de outros documentos que forem pertinentes ao seu objeto. É importante que no sistema SIAD os documentos sejam incluídos separadamente e não num único arquivo. Sempre que o convênio fizer referência a um documento, este documento deverá ser incluído no processo, para que possa ser consultado. Quanto mais completa for a instrução do processo, mais célere será sua tramitação nas instâncias da Universidade.\n",
      "----------------------------------------------------------------------\n",
      "4: O que é o Plano de Aplicação de Recursos?\n",
      "O Plano de Aplicação de Recursos é o documento que indica as rubricas de despesas em que os recursos recebidos para a execução do convênio serão aplicados. Ele costuma ser apresentado no formato de uma planilha, que contém todas as rubricas e os valores (ou percentuais, no caso de convênios celebrados sem valor fixo). O Plano de Aplicação de Recursos deve ser o mais completo possível e além das rubricas principais (recursos humanos, aquisição de materiais, contratação de serviços, etc.), deve conter desmembramentos, como, por exemplo: em caso de pagamento de recursos humanos, essa rubrica deve ser desmembrada para indicar quem serão os beneficiários dos recursos, em caso de aquisição de materiais, para indicação dos bens que serão adquiridos, em caso de contração de serviços, para indicação dos tipos de serviços que serão contratados, e assim por diante.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspirado no código do Leandro Carísio\n",
    "\n",
    "perg_resposta_esperada = []\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "  pr = test_set[i]\n",
    "\n",
    "  pergunta = pr['question']\n",
    "  resposta = pr['answer']\n",
    "  #contexto = [item['text'] for item in pr['context']]\n",
    "  #contexto = ', '.join(contexto)\n",
    " \n",
    "  perg_resposta_esperada.append({\"pergunta\": pergunta, \"resposta\": resposta})\n",
    "\n",
    "  if i < 5:\n",
    "    print(f\"{i}: {pergunta}\\n{resposta}\")\n",
    "    print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QAC_generator_prompt = \"\"\"You are a program that generates questions, answers to those questions, and context you used to answer those questions.\n",
    "You will receive many text documents in .json format with \"title\" and \"text\". For each document, you will generate a question, an answer and the context\n",
    "for this answer, that is, where in the text you can check the veracity of that answer.\n",
    "\n",
    "Your response will be in .json format, translated to Brazillian Portuguese,\n",
    "\n",
    "\n",
    "title: {title}\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DECRETO Nº 29.598, DE 02 DE FEVEREIRO DE 1989'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legis_set[3]['titulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# documents = []\n",
    "# all_titles = []\n",
    "\n",
    "# for item in test_set:\n",
    "#     if item['title'].lower() not in all_titles:\n",
    "#         documents.append({\n",
    "#                 \"title\": item['title'],\n",
    "#                 \"content\": item[\"text\"]\n",
    "#             }\n",
    "#         )\n",
    "#         all_titles.append(item['title'].lower())\n",
    "#     for link in item[\"links\"]:\n",
    "#         if link['target'].lower() in context_articles and link['target'].lower() not in all_titles:\n",
    "#             documents.append({\n",
    "#                 \"title\": link['target'],\n",
    "#                 \"content\": context_articles[link['target'].lower()]\n",
    "#             })\n",
    "#             all_titles.append(link['target'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_test_faq =[\n",
    "    {\n",
    "        \"question\": \"Em quais hipóteses a Procuradoria Geral pode exercer a representação judicial e extrajudicial de servidores da UNICAMP?\",\n",
    "        \"answer\": \"A Procuradoria Geral da UNICAMP integra a Advocacia Pública e está vinculada à Procuradoria Geral do Estado, para fins de atuação uniforme e coordenada, nos termos do artigo 101 da Constituição Estadual. Além disso, é o órgão de representação jurídica da Universidade e de assessoramento jurídico da Reitoria, consoante prevê o artigo 95 do Regimento Geral da UNICAMP. Desta forma, conforme previsão regimental, a Procuradoria Geral tem a função institucional de defender os interesses da universidade, enquanto autarquia estadual, estritamente vinculada ao atendimento do interesse público. A representação judicial ou extrajudicial de servidor com vínculo funcional permanente poderá ocorrer em caráter excepcional, nas hipóteses em que o ato impugnado decorrer do exercício de suas atribuições constitucionais, legais ou regulamentares, quando o ato praticado tiver seguido a orientação jurídica da Procuradoria e desde que não haja conflito de interesses, sempre com autorização expressa do Reitor.\",\n",
    "        \"context\": [\n",
    "            {\n",
    "                \"text\": 'texto do regimento',\n",
    "                \"title\": \"REGIMENTO GERAL DA UNIVERSIDADE ESTADUAL DE CAMPINAS\",\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"texto da constituição\",\n",
    "                \"title\": \"Constituição Federal\",\n",
    "            }\n",
    "    ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = []\n",
    "documents = []\n",
    "\n",
    "\n",
    "for item in dummy_test_faq:\n",
    "    for context in item['context']:\n",
    "        if context['title'] not in all_titles:\n",
    "            all_titles.append(context['title'].lower())\n",
    "            documents.append({\n",
    "                    \"title\": context['title'],\n",
    "                    \"content\": legis_set[context['title']] if context['title'] in legis_set else norms_set[context['title']]\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.11 s\n",
      "Wall time: 2.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "nlp = spacy.blank(\"pt\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "stride = 2\n",
    "max_length = 3\n",
    "\n",
    "def window(documents, stride=2, max_length=3):\n",
    "  treated_documents = []\n",
    "\n",
    "  for j, document in enumerate(tqdm(documents)):\n",
    "    doc_text = document['content']\n",
    "    doc = nlp(doc_text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    for i in range(0, len(sentences), stride):\n",
    "      segment = ' '.join(sentences[i:i + max_length])\n",
    "      treated_documents.append({\n",
    "          \"title\": document['title'],\n",
    "          \"contents\": document['title']+\". \"+segment,\n",
    "          \"segment\": segment\n",
    "      })\n",
    "      if i + max_length >= len(sentences):\n",
    "        break\n",
    "  return treated_documents\n",
    "\n",
    "\n",
    "artigos_segmentados = window(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 1.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pedro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "import array\n",
    "import pickle\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Definição de uma classe para índice invertido\n",
    "class IndiceInvertido:\n",
    "\n",
    "  # Recebe 'tokenizar', uma função tokenizadora\n",
    "  def __init__(self):\n",
    "    # Cria um índice invertido vazio\n",
    "    self.indice = {}\n",
    "    # Cria um índice de tamanho de documentos vazio\n",
    "    self.tamanho_doc = {}\n",
    "    # Guarda o total de documentos adicionados\n",
    "    self.n_docs = 0\n",
    "    # Tokenizador\n",
    "    self.stemmer = PorterStemmer()\n",
    "\n",
    "  def tokenizar(self, texto):\n",
    "    # Tokeniza\n",
    "    tokens = word_tokenize(texto)\n",
    "    # Converte para minúsculo, filtra stopwords e passa pelo Porter Stemer\n",
    "    tokens = [self.stemmer.stem(token.lower()) for token in tokens if token.lower() not in stopwords.words('english')]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "  def adiciona_doc(self, id_doc, conteudo_doc=None):\n",
    "    tokens = self.tokenizar(conteudo_doc)\n",
    "\n",
    "    contador_tokens_do_documento = Counter(tokens)\n",
    "    for token, n_ocorrencias in contador_tokens_do_documento.items():\n",
    "      self.indice.setdefault(token, {\"id_doc\": [], \"n_ocorrencias\": array.array(\"L\", [])})['id_doc'].append(id_doc)\n",
    "      self.indice.setdefault(token, {\"id_doc\": [], \"n_ocorrencias\": array.array(\"L\", [])})['n_ocorrencias'].append(n_ocorrencias)\n",
    "\n",
    "    self.n_docs += 1\n",
    "    self.tamanho_doc[id_doc] = len(tokens)\n",
    "\n",
    "class BM25:\n",
    "\n",
    "  def __init__(self, indiceInvertido=IndiceInvertido(), k1 = 0.9, b = 0.4, bias_adicionar_ao_idf = 0):\n",
    "    self.indiceInvertido = indiceInvertido\n",
    "    self.bias_adicionar_ao_idf = bias_adicionar_ao_idf\n",
    "    self.calcula_tam_medio_doc_no_indice()\n",
    "    self.k1 = k1\n",
    "    self.b = b\n",
    "    self.precalcula_idf()\n",
    "    self.reinicia_score_dos_indices()\n",
    "\n",
    "  def reinicia_score_dos_indices(self):\n",
    "    for token in self.indiceInvertido.indice.keys():\n",
    "      self.indiceInvertido.indice[token].pop('score', None)\n",
    "\n",
    "  def calcula_tam_medio_doc_no_indice(self):\n",
    "    self.avgdl = sum(self.indiceInvertido.tamanho_doc.values()) / self.indiceInvertido.n_docs\n",
    "\n",
    "  def precalcula_idf(self):\n",
    "    # Número de documento do corpus está presente no objeto indiceInvertido\n",
    "    N = self.indiceInvertido.n_docs\n",
    "    # Varre todos os tokens do índice. Os tokens são as chaves do indiceInvertido.indice\n",
    "    for token in self.indiceInvertido.indice.keys():\n",
    "      # O número de documentos que possui o token é calculado pelo tamanho da lista de id_doc:\n",
    "      n_doc_token = len(self.indiceInvertido.indice[token]['id_doc'])\n",
    "      # Isso já é o suficiente pra calcular o idf\n",
    "      idf_token = math.log( ((self.indiceInvertido.n_docs - n_doc_token + 0.5)/(n_doc_token + 0.5)) + self.bias_adicionar_ao_idf )\n",
    "      # E agora, vamos colocar essa informação no índice\n",
    "      self.indiceInvertido.indice[token]['idf'] = idf_token\n",
    "\n",
    "  def calcula_score_para_um_token_e_salva(self, token):\n",
    "    # O cálculo do BM25 para determinada query é a multiplicação do idf pela frequência do termo no documento * (k1 + 1)\n",
    "    # Além disso, é dividido pela frequencia do termo no documento + k1 * (1 - b + b * tamanho_doc/avgdl)\n",
    "    idf = self.indiceInvertido.indice[token]['idf']\n",
    "    # Juntando tudo, podemos calcular o score pelo BM25\n",
    "    zip_id_freq = zip(self.indiceInvertido.indice[token]['id_doc'], self.indiceInvertido.indice[token]['n_ocorrencias'])\n",
    "    bm25 = array.array(\"f\", [ idf * freq_token_no_doc * (self.k1 + 1) / (freq_token_no_doc + self.k1 * (1 - self.b + self.b * self.indiceInvertido.tamanho_doc[id_doc] / self.avgdl)) for (id_doc, freq_token_no_doc) in zip_id_freq ])\n",
    "    # Salva o bm25 no índice\n",
    "    self.indiceInvertido.indice[token]['score'] = bm25\n",
    "\n",
    "  def tokenizar(self, query):\n",
    "    return self.indiceInvertido.tokenizar(query)\n",
    "\n",
    "  def pesquisar(self, query):\n",
    "    # Tokeniza a query\n",
    "    tokens = self.tokenizar(query)\n",
    "\n",
    "    # Se não tem token para ser pesquisado, retorna conjunto vazio\n",
    "    if (len(tokens) == 0):\n",
    "      return []\n",
    "\n",
    "    # Guarda um dicionário onde a chave é o id do documento e o valor é o score desse documento para a query pesquisada\n",
    "    docs_retornado_com_score = Counter({})\n",
    "\n",
    "    # Faz a pesquisa de documentos. Para isso iteramos todos os tokens da query\n",
    "    for token in tokens:\n",
    "      # É possível que a query contenha algum termo que não foi indexado. Se isso ocorrer,\n",
    "      # entende-se que a frequência desse token em qualquer documento é 0, já que não pode ser encontrado\n",
    "      if token not in self.indiceInvertido.indice:\n",
    "        continue\n",
    "\n",
    "      # Pega a lista de documentos que será analisado\n",
    "      docs_que_tem_token = self.indiceInvertido.indice[token]['id_doc']\n",
    "\n",
    "      # Se for a primeira vez que esse token é pesquisado, é necessário calcular o score relacionado\n",
    "      # a ele e salvar. Se já tiver sido feito antes, já podemos buscar o cálculo pronto (que funciona\n",
    "      # como um cache. Isso é útil no caso de várias pesquisas seguidas)\n",
    "      if 'score' not in self.indiceInvertido.indice[token].keys():\n",
    "        self.calcula_score_para_um_token_e_salva(token)\n",
    "      score_dos_docs_deste_token = self.indiceInvertido.indice[token]['score']\n",
    "\n",
    "      # Agora já temos calculado o score de todos os documentos desse token. Só adiciona ao acumulador de score atual\n",
    "      # docs_retornado_com_score += score_dos_docs_deste_token -> Se fosse usar dict direto no índice seria assim, mas a memória não está aguentando guardar os scores de ambos\n",
    "      for id_doc, score_par_doc_token in zip(docs_que_tem_token, score_dos_docs_deste_token):\n",
    "        docs_retornado_com_score[id_doc] += score_par_doc_token\n",
    "\n",
    "    # Agora converte esse dict em uma lista de tuplas com a chave (id_doc) e valor (score_do_doc)\n",
    "    docs_com_score = list(docs_retornado_com_score.items())\n",
    "\n",
    "    # E ordena do mais relevante para o menos relevante\n",
    "    return sorted(docs_com_score, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qual', 'maior', 'planeta', 'sistema', 'solar', '?']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iidx = IndiceInvertido()\n",
    "iidx.tokenizar('Qual o maior planeta do sistema solar?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se True, gera o índice invertido e salva em um pickle. Se False, apenas recupera o pickle do drive\n",
    "GERAR_INDICE_INVERTIDO = True\n",
    "ARQUIVO_INDICE_INVERTIDO = 'iidx_artigos_segmentados' # A função salva em 2 arquivos, então ela mesma coloca a extensão pickle\n",
    "\n",
    "# Se True, gera as respostas. Se False, apenas recupera o pickle do drive\n",
    "AGREGAR_DOCUMENTOS = True\n",
    "ARQUIVO_AGREGADO = 'respostas_obtidas.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def salvar_indice_em_arquivo_pickle(indice_invertido):\n",
    "  nome_arquivo_base = f\"{'../input/Raw Text/Rag Data/'}{ARQUIVO_INDICE_INVERTIDO}\"\n",
    "\n",
    "  with open(f'{nome_arquivo_base}_indice.pickle', 'wb') as f:\n",
    "    pickle.dump(indice_invertido.indice, f)\n",
    "  with open(f'{nome_arquivo_base}_tamanho_doc.pickle', 'wb') as f:\n",
    "    pickle.dump(indice_invertido.tamanho_doc, f)\n",
    "\n",
    "def recuperar_indice_em_arquivo_pickle():\n",
    "  nome_arquivo_base = f\"{'../input/Raw Text/Rag Data/'}{ARQUIVO_INDICE_INVERTIDO}\"\n",
    "  idx = IndiceInvertido()\n",
    "\n",
    "  with open(f'{nome_arquivo_base}_indice.pickle', 'rb') as f:\n",
    "    idx.indice = pickle.load(f)\n",
    "  with open(f'{nome_arquivo_base}_tamanho_doc.pickle', 'rb') as f:\n",
    "    idx.tamanho_doc = pickle.load(f)\n",
    "  idx.n_docs = len(idx.tamanho_doc)\n",
    "\n",
    "  return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 segmentos indexados\n",
      "CPU times: total: 34.6 s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iidx = IndiceInvertido()\n",
    "\n",
    "if GERAR_INDICE_INVERTIDO:\n",
    "  # Vamos usar o próprio índice como um id para o segmento. Vai facilitar a vida depois\n",
    "  # art_seg['contents'] tem o título e 3 frases do artigo\n",
    "  for id, art_seg in enumerate(artigos_segmentados):\n",
    "    iidx.adiciona_doc(id, art_seg['contents'])\n",
    "\n",
    "    if id % 10000 == 0:\n",
    "      print(f'{id} segmentos indexados')\n",
    "\n",
    "  salvar_indice_em_arquivo_pickle(iidx)\n",
    "else:\n",
    "  iidx = recuperar_indice_em_arquivo_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, art_seg in enumerate(artigos_segmentados):\n",
    "    iidx.adiciona_doc(id, art_seg['contents'])\n",
    "\n",
    "    if id % 100 == 0:\n",
    "      print(f'{id} segmentos indexados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "buscador = BM25(iidx, 0.82, 0.68, 1)\n",
    "buscador = BM25(iidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta e resposta esperada: \n",
      "{'pergunta': 'Como ocorrem as atividades de cooperação, pesquisa, ensino, extensão e prestação de serviços entre a Unicamp e terceiros, pessoas físicas ou jurídicas?', 'resposta': 'Nos termos do art. 1° da Deliberação CONSU-A-016/2022, a atuação da Universidade em atividades de cooperação, pesquisa, ensino, extensão e prestação de serviços junto a terceiros, pessoas físicas ou jurídicas, deve ocorrer mediante prévia celebração de convênios, contratos e instrumentos similares.'}\n",
      "-----------------------------------------------------------------\n",
      "10 primeiros conteúdos retornados pelo BM25\n",
      "\n",
      "Segmento_id: 1400. Score: -3.803192377090454\n",
      "Title: Constituição Federal\n",
      "Contents: Constituição Federal. Parágrafo único. A lei garantirá tratamento especial à propriedade produtiva e fixará normas para o cumprimento dos requisitos relativos a sua função social.   Art. 186.\n",
      "-----------------------------------------------------------------\n",
      "Segmento_id: 1119. Score: -4.642447471618652\n",
      "Title: Constituição Federal\n",
      "Contents: Constituição Federal. SEÇÃO VII\n",
      "DOS TRIBUNAIS E JUÍZES MILIT ARES\n",
      "  Art. 122. São órgãos da Justiça Militar:\n",
      "I - o Superior Tribunal Militar;\n",
      "II - os Tribunais e Juízes Militares instituídos por lei.   Art. 123.\n",
      "-----------------------------------------------------------------\n",
      "Segmento_id: 172. Score: -6.317612379789352\n",
      "Title: REGIMENTO GERAL DA UNIVERSIDADE ESTADUAL DE CAMPINAS\n",
      "Contents: REGIMENTO GERAL DA UNIVERSIDADE ESTADUAL DE CAMPINAS. A Universidade abster -se-á \n",
      "de instituir ações de extensão desvinculadas das \n",
      "atividade s de ensino e pesquisa do Instituto ou \n",
      "Faculdade proponente. Artigo 73– F. Os cursos de extensão visam a \n",
      "difusão e compartilhamento de conhecimentos e técnicas de trabalho entre universidade e comunidade. Parágrafo único.\n",
      "-----------------------------------------------------------------\n",
      "Segmento_id: 547. Score: -8.238170474767685\n",
      "Title: REGIMENTO GERAL DA UNIVERSIDADE ESTADUAL DE CAMPINAS\n",
      "Contents: REGIMENTO GERAL DA UNIVERSIDADE ESTADUAL DE CAMPINAS. Revogado pela Deliberação Consu -A-\n",
      "52/2020;  \n",
      "III. classificação no Vestibular Unicamp ou \n",
      "em outros sistemas de seleção estabelecidos pelo Conselho Universitário . Artigo 207.\n",
      "-----------------------------------------------------------------\n",
      "Segmento_id: 685. Score: -8.755431175231934\n",
      "Title: REGIMENTO GERAL DA UNIVERSIDADE ESTADUAL DE CAMPINAS\n",
      "Contents: REGIMENTO GERAL DA UNIVERSIDADE ESTADUAL DE CAMPINAS. na Faculdade de Educação Física:  \n",
      "a) Bacharelado em Educação Física;  \n",
      "b) Licenciatura em Educação Física. XVII. na Faculdade de Engenharia Agr ícola:  \n",
      "a) Engenharia Agrícola.\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Pergunta e resposta esperada: ')\n",
    "print(perg_resposta_esperada[1])\n",
    "\n",
    "resultado_bm25 = buscador.pesquisar(perg_resposta_esperada[1]['pergunta'])\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "print('10 primeiros conteúdos retornados pelo BM25\\n')\n",
    "for i in range(5):\n",
    "  segmento_id = resultado_bm25[i][0]\n",
    "  score = resultado_bm25[i][1]\n",
    "\n",
    "  title = artigos_segmentados[segmento_id]['title']\n",
    "  contents = artigos_segmentados[segmento_id]['contents']\n",
    "  segment = artigos_segmentados[segmento_id]['segment']\n",
    "\n",
    "  print(f'Segmento_id: {segmento_id}. Score: {score}')\n",
    "  print(f\"Title: {title}\")\n",
    "  print(f\"Contents: {contents}\")\n",
    "  print('-----------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
